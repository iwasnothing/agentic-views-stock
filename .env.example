# Required environment variables for the Agentic Decision Maker
# Copy this file to .env and fill in your actual values

# ─── LLM Provider ────────────────────────────────────────────────────────────
# When running with Docker, the backend routes through the LiteLLM proxy.
# OPENAI_BASE_URL is overridden to http://litellm:4000/v1 in docker-compose.yml.
# For local (non-Docker) development, point directly at your provider:
OPENAI_BASE_URL=https://api.openai.com/v1

# API key for authentication (used by LiteLLM proxy to call the upstream provider)
OPENAI_API_KEY=your-api-key-here

# Model name to use (must match a model_name in litellm_config.yaml when using Docker)
OPENAI_MODEL_NAME=gpt-4

# Perplexity API key for financial search
PERPLEXITY_API_KEY=your-perplexity-key-here

# ─── LiteLLM Proxy (Docker only) ─────────────────────────────────────────────
# Master key to protect the LiteLLM admin API. Change this to a secure value.
LITELLM_MASTER_KEY=sk-litellm-master-key

# ─── Application Settings ────────────────────────────────────────────────────
# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# LLM call settings — timeout per request and max retry attempts
LLM_TIMEOUT_SECONDS=60
LLM_MAX_RETRIES=5

# External API call settings (Perplexity search, etc.)
API_TIMEOUT_SECONDS=60
API_MAX_RETRIES=5

# LangGraph recursion limit (max graph steps per invocation)
# ReAct agents loop LLM→tool; each round = 2 steps. Default 25 is too low.
RECURSION_LIMIT=100
